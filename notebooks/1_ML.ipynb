{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94afd3f",
   "metadata": {},
   "source": [
    "# Predictive maintenance for turbofan engine example\n",
    "\n",
    "## Part 2: Linear Regression\n",
    "\n",
    "\n",
    "Based on open dataset provided by NASA at:\n",
    "https://data.nasa.gov/widgets/vrks-gjie\n",
    "\n",
    "dataset can be downloaded at: http://ti.arc.nasa.gov/c/6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the TensorBoard notebook extension (optional, can be started from the command line)\n",
    "#%load_ext tensorboard\n",
    "\n",
    "# Select a plotting style\n",
    "#plt.style.use('dark_background')\n",
    "plt.style.use('seaborn')\n",
    "#plt.style.available\n",
    "\n",
    "SCALE = 1\n",
    "SEED = 1\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015089f",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeead56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "data_root = 'data/'\n",
    "original_dir = data_root + 'original/'\n",
    "dataset_dir = data_root + 'dataset/'\n",
    "\n",
    "train_data = pd.read_csv(dataset_dir + 'train_data.csv')\n",
    "test_data = pd.read_csv(dataset_dir + 'test_data.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af08080d",
   "metadata": {},
   "source": [
    "### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the lifecycles\n",
    "one_engine = []\n",
    "for i, r in train_data.iterrows():\n",
    "    rul = r['RUL']\n",
    "    one_engine.append(rul)\n",
    "    if rul == 0:\n",
    "        plt.plot(one_engine)\n",
    "        one_engine = []\n",
    "        \n",
    "#plt.grid()\n",
    "plt.xlabel('Cycles')\n",
    "plt.ylabel('RUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99adb50a",
   "metadata": {},
   "source": [
    "## Machine Learning Application\n",
    "\n",
    "We will split the data in 4 parts: x_train, y_train, x_test, y_test.\n",
    "\n",
    "(actually the dataset is already split)\n",
    "- x is for the sensor data\n",
    "- y is for the known Remaining Useful Life\n",
    "- train is for data we will use to train the model (we will use the known RUL in the training)\n",
    "- test is for data validation... we will apply predictions and compute models performance metrics using the known RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle train data frame and apply scaling factor\n",
    "train_data = train_data.sample(frac=SCALE, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# prepare a x frame with useful data and a y frame with RUL value\n",
    "x_train = train_data.drop(columns=['Unit', 'Cycle', 'RUL'])\n",
    "y_train = train_data['RUL']\n",
    "\n",
    "x_test = test_data.drop(columns=['Cycle', 'RUL'])\n",
    "\n",
    "y_test = test_data['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3290a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data normalization\n",
    "\n",
    "mean = x_train.mean()\n",
    "std = x_train.std()\n",
    "\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "\n",
    "x_train = x_train.dropna(axis=1, how='any')\n",
    "x_test = x_test.dropna(axis=1, how='any')\n",
    "\n",
    "#x_test = np.asarray(x_test).astype('float32')\n",
    "\n",
    "\n",
    "# what's the shape now we dropped some columns? create a variable to use in \n",
    "# get_model_v1 function call\n",
    "(lines,shape) = x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c5576",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build a ML model\n",
    "\n",
    "def get_model_v1(shape):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape, name='input_layer'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu', name='dense_n1'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu', name='dense_n2'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu', name='dense_n3'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu', name='dense_n4'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu', name='dense_n5'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu', name='dense_n6'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu', name='dense_n7'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu', name='dense_n8'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu', name='dense_n9'))\n",
    "    model.add(keras.layers.Dense(1, name='output'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss      = 'mse',\n",
    "                  metrics   = ['mae', 'mse'],\n",
    "                 )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instanciate the model\n",
    "\n",
    "model = get_model_v1((shape,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9bb33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# Configure callback for vizualization of the training data in tensorboard\n",
    "if not os.path.exists('logs/'):\n",
    "    os.mkdir('logs')\n",
    "\n",
    "log_dir = 'logs/fit/' + f'S{SCALE}_E{EPOCHS}_' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#%tensorboard --logdir ./logs\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs          = EPOCHS,\n",
    "                    batch_size      = 20,\n",
    "                    verbose         = 1,\n",
    "                    validation_data = (x_test, y_test),\n",
    "                    callbacks = [tensorboard_callback],)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"\\n\\nTraining time: {end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592fe119",
   "metadata": {},
   "source": [
    "## Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a4322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=history.history)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85602513",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"min(val_mae) : {:.4f}\".format(min(history.history['val_mae'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, figsize=(8,6), \n",
    "                 plot={\"Accuracy\":['accuracy','val_accuracy'], 'Loss':['loss', 'val_loss']},\n",
    "                 save_as='auto'):\n",
    "    \"\"\"\n",
    "    Show history\n",
    "    args:\n",
    "        history: history\n",
    "        figsize: fig size\n",
    "        plot: list of data to plot : {<title>:[<metrics>,...], ...}\n",
    "    \"\"\"\n",
    "    fig_id=0\n",
    "    for title,curves in plot.items():\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.title(title)\n",
    "        plt.ylabel(title)\n",
    "        plt.xlabel('Epoch')\n",
    "        for c in curves:\n",
    "            plt.plot(history.history[c])\n",
    "        plt.legend(curves, loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_history(history, plot={'MSE' :['mse', 'val_mse'],\n",
    "                            'MAE' :['mae', 'val_mae'],\n",
    "                            'LOSS':['loss','val_loss']}, save_as='01-history')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8cc432",
   "metadata": {},
   "source": [
    "## Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476196e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "\n",
    "selection = 56\n",
    "\n",
    "engine = x_test.iloc[selection]\n",
    "engine_rul = y_test.iat[selection]\n",
    "print('Data (denormalized):\\n\\n', engine.dropna(axis=0, how='any')  * std + mean, '\\n\\n')\n",
    "print('RUL = ', engine_rul)\n",
    "\n",
    "engine = np.array(engine).reshape(1, shape)\n",
    "\n",
    "print('\\n\\n---\\n\\n')\n",
    "\n",
    "predictions = model.predict(engine)\n",
    "print('Prediction  : {:.0f} Cycles'.format(predictions[0][0]))\n",
    "print('Real RUL    : {:.0f} Cycles'.format(engine_rul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a8ba27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO confusion matrix\n",
    "predictions = []\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    engine = x_test.iloc[i]\n",
    "    engine = np.array(engine).reshape(1, shape)\n",
    "    prediction = model.predict(engine)\n",
    "    predictions.append(prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(predictions, y_test);\n",
    "\n",
    "# Add a line\n",
    "x = [0, 150]\n",
    "y = x\n",
    "plt.plot(x,y, color='lightgreen');\n",
    "\n",
    "# Layout\n",
    "plt.xlabel('Predictions');\n",
    "plt.ylabel('Reality');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811cfbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obviously the ML algo doesn't do much... but this was for benchmarking the DOKS infrastructures anyway :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1628d823",
   "metadata": {},
   "source": [
    "# Data Preparation for Engine Predictive Maintenance Examples\n",
    "\n",
    "WARNING: parameter names sourced from MATLAB predictive maintenance webinar. Information is not cross confirmed (NASA data source names it \"sensor measurement x\").\n",
    "\n",
    "WARNING: data in the 4 different datasets provided are not homogeneous. Demo is developed using data in train/test_FD001.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbe79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = ['Unit', 'Cycle', 'OpSet1', 'OpSet2', 'OpSet3', \n",
    "                'FanInletTemp', 'LPCOutletTemp', 'HPCOutletTemp', 'LPTOutletTemp', \n",
    "                'FanInletPres', 'BypassDuctPres', 'TotalHPCOutletPres', \n",
    "                'PhysFanSpeed', 'PhysCoreSpeed', 'EnginePresRatio',\n",
    "                'StaticHPCOutletPres', 'FuelFlowRatio', \n",
    "                'CorrFanSpeed', 'CorrCoreSpeed',\n",
    "                'BypassRatio', 'BurnerFuelAirRatio', \n",
    "                'BleedEnthalpy', 'DemandFanSpeed', \n",
    "                'DemandCorrFanSpeed', 'HPTCoolantBleed', 'LPTCoolantBleed'\n",
    "               ]\n",
    "\n",
    "COLUMNS_W_RUL = COLUMNS + ['RUL']\n",
    "\n",
    "SUFFIXES = ['FD001.txt'] # Select only 1 dataset\n",
    "#SUFFIXES = ['FD001.txt', 'FD002.txt', 'FD003.txt', 'FD004.txt'] # Select full data (not recommended)\n",
    "\n",
    "data_root = 'data/'\n",
    "original_dir = data_root + 'original/'\n",
    "dataset_dir = data_root + 'dataset/'\n",
    "filename = 'CMAPSSData.zip'\n",
    "original_file = original_dir + filename\n",
    "url = 'http://ti.arc.nasa.gov/c/6'\n",
    "\n",
    "if not os.path.exists(data_root):\n",
    "    os.mkdir(data_root)\n",
    "\n",
    "if not os.path.exists(data_root + 'original/'):\n",
    "    os.mkdir(data_root + 'original/')\n",
    "    \n",
    "if not os.path.exists(original_file):\n",
    "    print('Downloading data...')\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(original_file, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    print('Done.')\n",
    "else:\n",
    "    print('Found original data file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with zipfile.ZipFile(original_file) as z:\n",
    "        z.extractall(original_dir)\n",
    "        print('Extracted all files')\n",
    "except:\n",
    "    print('Bad file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(original_dir + 'train_FD001.txt', sep=' ', header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08223464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_engine_data(df):\n",
    "    # Cleanup and label the columns\n",
    "    df.dropna(axis=1, how='any', inplace=True)\n",
    "    df.columns = COLUMNS\n",
    "\n",
    "    # Compute and add Remaining Useful Life in a new column\n",
    "    last_cycles = df.groupby(['Unit'], sort=False)['Cycle'].max().reset_index().rename(columns={'Cycle': 'LastCycle'})\n",
    "    df = pd.merge(df, last_cycles, how='inner', on='Unit')\n",
    "    df['RUL'] = df['LastCycle'] - df['Cycle']\n",
    "    df.drop(columns={'LastCycle'}, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = format_engine_data(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dataset_dir):\n",
    "    os.mkdir(dataset_dir)\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "\n",
    "for suffix in SUFFIXES:\n",
    "    df = pd.read_csv(original_dir + 'train_' + suffix, sep=' ', header=None)\n",
    "    df = format_engine_data(df)\n",
    "    train_data = train_data.append(df)\n",
    "    \n",
    "train_data.columns = COLUMNS_W_RUL\n",
    "    \n",
    "train_data.to_csv(dataset_dir + 'train_data.csv', index=None)\n",
    "print('Training data ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d65c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame()\n",
    "\n",
    "for suffix in SUFFIXES:\n",
    "    df = pd.read_csv(original_dir + 'test_' + suffix, sep=' ', header=None)\n",
    "    df = format_engine_data(df)\n",
    "    df = df.groupby('Unit').last()\n",
    "    \n",
    "    rul = pd.read_csv(original_dir + 'RUL_' + suffix, header=None)\n",
    "    rul.columns={'RUL'}\n",
    "    rul.index = rul.index + 1\n",
    "    df['RUL'] = rul['RUL']\n",
    "    \n",
    "    test_data = test_data.append(df)\n",
    "\n",
    "COLUMNS_W_RUL.pop(0)\n",
    "test_data.columns = COLUMNS_W_RUL\n",
    "test_data.to_csv(dataset_dir + 'test_data.csv')\n",
    "\n",
    "print('Test data ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b410d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
